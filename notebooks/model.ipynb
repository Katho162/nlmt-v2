{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "957eb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d80eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"../data\")\n",
    "roles_path = data_folder / \"roles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b9c6f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(roles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6af628bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = set(col.split(\" \", 1)[1] for col in df.columns[1:])\n",
    "merged_data = pd.DataFrame(index=df.index)\n",
    "\n",
    "for lang in languages:\n",
    "    merged_data[lang] = 0\n",
    "    for prefix in [\"Studying\", \"Fluent\", \"Native\"]:\n",
    "        col = f\"{prefix} {lang}\"\n",
    "        if col in df.columns:\n",
    "            merged_data[lang] |= df[col].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "merged_data = merged_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbb9f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f1219b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(merged_data.values)\n",
    "dataset = TensorDataset(X_tensor, X_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f86d3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAERecommender(nn.Module):\n",
    "    def __init__(self, num_languages, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.num_languages = num_languages\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_languages, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Mean and log-variance for latent space\n",
    "        self.fc_mu = nn.Linear(256, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_languages)\n",
    "        )\n",
    "        \n",
    "        # Language embeddings (optional)\n",
    "        self.language_embeddings = nn.Embedding(num_languages, latent_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # Optionally add mean of language embeddings for known languages\n",
    "        lang_idx = x.nonzero(as_tuple=False)[:, 1]  # indices of known languages\n",
    "        if len(lang_idx) > 0:\n",
    "            z += self.language_embeddings(lang_idx).mean(dim=0)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "651ec4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    bce = nn.BCEWithLogitsLoss()(recon_x, x)\n",
    "    # KL Divergence\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return bce + kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db6e5921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1528\n",
      "Epoch 2, Loss: 0.1319\n",
      "Epoch 3, Loss: 0.1310\n",
      "Epoch 4, Loss: 0.1289\n",
      "Epoch 5, Loss: 0.1282\n",
      "Epoch 6, Loss: 0.1281\n",
      "Epoch 7, Loss: 0.1273\n",
      "Epoch 8, Loss: 0.1264\n",
      "Epoch 9, Loss: 0.1249\n",
      "Epoch 10, Loss: 0.1241\n",
      "Epoch 11, Loss: 0.1228\n",
      "Epoch 12, Loss: 0.1222\n",
      "Epoch 13, Loss: 0.1217\n",
      "Epoch 14, Loss: 0.1215\n",
      "Epoch 15, Loss: 0.1210\n",
      "Epoch 16, Loss: 0.1209\n",
      "Epoch 17, Loss: 0.1206\n",
      "Epoch 18, Loss: 0.1202\n",
      "Epoch 19, Loss: 0.1199\n",
      "Epoch 20, Loss: 0.1199\n",
      "Epoch 21, Loss: 0.1196\n",
      "Epoch 22, Loss: 0.1196\n",
      "Epoch 23, Loss: 0.1193\n",
      "Epoch 24, Loss: 0.1190\n",
      "Epoch 25, Loss: 0.1188\n",
      "Epoch 26, Loss: 0.1189\n",
      "Epoch 27, Loss: 0.1188\n",
      "Epoch 28, Loss: 0.1187\n",
      "Epoch 29, Loss: 0.1186\n",
      "Epoch 30, Loss: 0.1188\n"
     ]
    }
   ],
   "source": [
    "model = VAERecommender(X_tensor.shape[1], latent_dim=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(batch_x)\n",
    "        loss = vae_loss(recon, batch_y, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7cb98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Korean', 'Mandarin', 'Spanish', 'French', 'Indonesian', 'German', 'Arabic', 'Filipino', 'Russian', 'Conlangs / Sign Language']\n"
     ]
    }
   ],
   "source": [
    "def recommend_languages_vae(model, user_vector, top_k=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(user_vector, dtype=torch.float32).unsqueeze(0)\n",
    "        recon, _, _ = model(input_tensor)\n",
    "        preds = torch.sigmoid(recon).squeeze().numpy()\n",
    "    \n",
    "    preds[user_vector > 0] = -1  # mask known languages\n",
    "    recommended_indices = preds.argsort()[-top_k:][::-1]\n",
    "    return [merged_data.columns[i] for i in recommended_indices]\n",
    "\n",
    "# Example: New user\n",
    "new_user_vector = np.zeros(merged_data.shape[1])\n",
    "new_user_vector[merged_data.columns.get_loc(\"English\")] = 1\n",
    "new_user_vector[merged_data.columns.get_loc(\"Japanese\")] = 1\n",
    "\n",
    "recommendations = recommend_languages_vae(model, new_user_vector)\n",
    "print(recommendations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
